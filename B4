import os
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
# Initialize Spark session
spark = SparkSession.builder.appName("WeatherAnalysis").getOrCreate()
# Base path to the cleaned weather data
base_path = "/content/cleaned_weather_data"
# Initialize a dictionary to store the hottest days per year
hottest_days = {}
# Loop through the years to find the hottest day
for year in range(2015, 2023):
year_dir = os.path.join(base_path, str(year))
# Check if the year directory exists
if not os.path.exists(year_dir):
print(f"Year directory not found: {year_dir}")
continue
for filename in os.listdir(year_dir):
if filename.endswith('.csv'):
file_path = os.path.join(year_dir, filename)
# Read the CSV file into a DataFrame
df = spark.read.csv(file_path, header=True, inferSchema=True)
# Check if DataFrame is empty
if df.rdd.isEmpty():
print(f"Skipping empty file: {filename}")
continue
# Ensure 'MAX' column exists, otherwise create it with NULL values
if "MAX" not in df.columns:
df = df.withColumn("MAX", F.lit(None))
# Find the hottest day for the current DataFrame
max_temp = df.agg(F.max("MAX")).collect()[0][0]
if max_temp is not None:
max_day = df.filter(df["MAX"] == max_temp).orderBy(F.desc("DATE")).first()
if max_day:
# Store only the first hottest day per year
if year not in hottest_days:
hottest_days[year] = (max_day.STATION, max_day.NAME, max_day.DATE, max_day.MAX)
# Convert results to a DataFrame for display
if hottest_days:
hottest_days_list = [(year, *data) for year, data in hottest_days.items()]
hottest_days_df = spark.createDataFrame(hottest_days_list, ["YEAR", "STATION", "NAME", "DATE", "MAX"])
hottest_days_df.show()
else:
print("No hottest days found across the datasets.")





import os
from pyspark.sql import SparkSession, functions as F

# Initialize Spark session
spark = SparkSession.builder.appName("Hottest Day Analysis").getOrCreate()

# Base path to weather data
base_path = "/content/cleaned_weather_data"

# Find hottest day per year
def find_hottest_days(start_year=2015, end_year=2023):
    hottest_days = []
    
    for year in range(start_year, end_year):
        year_dir = os.path.join(base_path, str(year))
        if not os.path.exists(year_dir):
            continue

        for file in os.listdir(year_dir):
            if file.endswith('.csv'):
                df = spark.read.csv(os.path.join(year_dir, file), header=True, inferSchema=True)
                if df.rdd.isEmpty() or "MAX" not in df.columns:
                    continue
                
                hottest_day = df.orderBy(F.desc("MAX")).select("STATION", "NAME", "DATE", "MAX").first()
                if hottest_day:
                    hottest_days.append((year, *hottest_day))

    if hottest_days:
        spark.createDataFrame(hottest_days, ["YEAR", "STATION", "NAME", "DATE", "MAX"]).show()

# Run function
find_hottest_days()

# Stop Spark session
spark.stop()

